{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sentiments = pd.read_csv('../data/interim/bitcoin_all_tweets_sentiments_20210101-20210930.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sentiments.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sentiments['dateTime']= pd.to_datetime(tweets_sentiments['dateTime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sentiments = tweets_sentiments[['id', 'dateTime', 'prediction']]\n",
    "\n",
    "tweets_sentiments.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty_mins_span = tweets_sentiments.groupby('prediction').resample('30min', on='dateTime').count()\n",
    "\n",
    "one_h_span = tweets_sentiments.groupby('prediction').resample('1H', on='dateTime').count()\n",
    "\n",
    "two_h_span = tweets_sentiments.groupby('prediction').resample('2H', on='dateTime').count()\n",
    "\n",
    "daily_span = tweets_sentiments.groupby('prediction').resample('D', on='dateTime').count()\n",
    "\n",
    "fifteen_mins_span = tweets_sentiments.groupby('prediction').resample('15min', on='dateTime').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty_mins_span = thirty_mins_span.unstack('prediction', fill_value=0)\n",
    "thirty_mins_span = thirty_mins_span[('id')]\n",
    "\n",
    "one_h_span = one_h_span.unstack('prediction', fill_value=0)\n",
    "one_h_span = one_h_span[('id')]\n",
    "\n",
    "two_h_span = two_h_span.unstack('prediction', fill_value=0)\n",
    "two_h_span = two_h_span[('id')]\n",
    "\n",
    "daily_span = daily_span.unstack('prediction', fill_value=0)\n",
    "daily_span = daily_span[('id')]\n",
    "\n",
    "fifteen_mins_span = fifteen_mins_span.unstack('prediction', fill_value=0)\n",
    "fifteen_mins_span = fifteen_mins_span[('id')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_h_span.index.name = None\n",
    "two_h_span.columns.name = 'index'\n",
    "\n",
    "#two_h_span.loc['2021-09-10':'2021-09-30']\n",
    "daily_span.index.name = None\n",
    "daily_span.columns.name = 'index'\n",
    "\n",
    "#daily_span.loc['2021-09-10':'2021-09-30']\n",
    "\n",
    "one_h_span.index.name = None\n",
    "one_h_span.columns.name = 'index'\n",
    "\n",
    "thirty_mins_span.index.name = None\n",
    "thirty_mins_span.columns.name = 'index'\n",
    "\n",
    "\n",
    "fifteen_mins_span.index.name = None\n",
    "fifteen_mins_span.columns.name = 'index'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_percentage(df):\n",
    "    df['total'] = df['negative'] + df['neutral'] + df['positive']\n",
    "    df['pos_percent'] = df['positive'] / df['total'] * 100 \n",
    "    df['neu_percent'] = df['neutral'] / df['total'] * 100\n",
    "    df['neg_percent'] = df['negative'] / df['total'] * 100\n",
    "\n",
    "calc_percentage(thirty_mins_span)\n",
    "calc_percentage(one_h_span)\n",
    "calc_percentage(two_h_span)\n",
    "calc_percentage(daily_span)\n",
    "calc_percentage(fifteen_mins_span)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = daily_span\n",
    "\n",
    "# Define the upper limit, lower limit, interval of Y axis and colors\n",
    "y_LL = 0\n",
    "y_UL = int(plot.iloc[:, 1:].max().max()*1.1)\n",
    "#y_UL = 50000\n",
    "y_interval = 4000\n",
    "mycolors = ['tab:red', 'tab:blue', 'tab:green', 'tab:orange']    \n",
    "\n",
    "# Draw Plot and Annotate\n",
    "fig, ax = plt.subplots(1,1,figsize=(16, 9), dpi= 80)    \n",
    "\n",
    "columns = plot.columns[:3]  \n",
    "for i, column in enumerate(columns):    \n",
    "    valt = plot[column].values\n",
    "    plt.plot(plot.index.values, plot[column].values, lw=1.5, color=mycolors[i])    \n",
    "    plt.text(plot.shape[0]+1, plot[column].values[-1], column, fontsize=14, color=mycolors[i])\n",
    "\n",
    "# Draw Tick lines  \n",
    "for y in range(y_LL, y_UL, y_interval):    \n",
    "    plt.hlines(y, xmin=0, xmax=71, colors='black', alpha=0.3, linestyles=\"--\", lw=0.5)\n",
    "\n",
    "# Decorations    \n",
    "plt.tick_params(axis=\"both\", which=\"both\", bottom=False, top=False,    \n",
    "                labelbottom=True, left=False, right=False, labelleft=True)        \n",
    "\n",
    "# Lighten borders\n",
    "plt.gca().spines[\"top\"].set_alpha(.3)\n",
    "plt.gca().spines[\"bottom\"].set_alpha(.3)\n",
    "plt.gca().spines[\"right\"].set_alpha(.3)\n",
    "plt.gca().spines[\"left\"].set_alpha(.3)\n",
    "\n",
    "plt.title('a sample title', fontsize=22)\n",
    "plt.yticks(range(y_LL, y_UL, y_interval), [str(y) for y in range(y_LL, y_UL, y_interval)], fontsize=12)    \n",
    "plt.xticks(range(0, plot.shape[0], 24), plot.index.values[::24], horizontalalignment='left', fontsize=12)    \n",
    "\n",
    "\n",
    "plt.ylim(y_LL, y_UL)    \n",
    "plt.xlim(-2, 80)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = thirty_mins_span\n",
    "\n",
    "x = plot.index.values\n",
    "#pos = plot['positive']\n",
    "#neu = plot['neutral']\n",
    "#neg = plot['negative']\n",
    "\n",
    "pos = plot['pos_percent']\n",
    "neu = plot['neu_percent']\n",
    "neg = plot['neg_percent']\n",
    "\n",
    "mycolors = ['tab:red', 'tab:blue', 'tab:green', 'tab:orange']    \n",
    "\n",
    "plt.plot(x,pos, color=mycolors[2])\n",
    "\n",
    "plt.plot(x,neu, color=mycolors[1])\n",
    "plt.plot(x,neg, color=mycolors[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty_mins_span = thirty_mins_span.reset_index().rename(columns={'index':'datetime'})\n",
    "one_h_span = one_h_span.reset_index().rename(columns={'index':'datetime'})\n",
    "two_h_span = two_h_span.reset_index().rename(columns={'index':'datetime'})\n",
    "daily_span = daily_span.reset_index().rename(columns={'index':'datetime'})\n",
    "fifteen_mins_span = fifteen_mins_span.reset_index().rename(columns={'index':'datetime'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty_mins_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_prices = pd.read_csv('../data/external/Bitstamp_BTCUSD_2021_minute_final.csv', header = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_prices[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd = bitcoin_prices[['date', 'open', 'Volume BTC']]\n",
    "bpd['date'] = pd.to_datetime(bpd[\"date\"], format=\"%Y-%m-%d %H:%M:%S\", errors='coerce', utc=True)\n",
    "#bpd['Date'] = bpd['SPdateTime'].dt.strftime('%Y-%m-%d')\n",
    "bpd = bpd.set_index('date')\n",
    "#bpd.reset_index()\n",
    "\n",
    "bpd.info()\n",
    "bpd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def fetch_prices(df, span_mins):\n",
    "    c_dts = df.datetime\n",
    "    dts_1 = c_dts + datetime.timedelta(minutes=span_mins)\n",
    "    dts_2 = c_dts + datetime.timedelta(minutes=(span_mins*2))\n",
    "    dts_3 = c_dts + datetime.timedelta(minutes=(span_mins*3))\n",
    "    dts_4 = c_dts + datetime.timedelta(minutes=(span_mins*4))\n",
    "\n",
    "    df['cp'] = bpd.loc[c_dts].reset_index()['open']\n",
    "    df['1spanp'] = bpd.loc[dts_1].reset_index()['open']\n",
    "    df['2spanp'] = bpd.loc[dts_2].reset_index()['open']\n",
    "    df['3spanp'] = bpd.loc[dts_3].reset_index()['open']\n",
    "    df['4spanp'] = bpd.loc[dts_4].reset_index()['open']\n",
    "\n",
    "fetch_prices(thirty_mins_span, 30)\n",
    "fetch_prices(one_h_span, 60)\n",
    "fetch_prices(two_h_span, 120)\n",
    "#fetch_prices(two_h_span, 90)\n",
    "fetch_prices(fifteen_mins_span, 15)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_trade_vol(df, span_mins):\n",
    "    c_dts = df.datetime\n",
    "    vols = bpd.resample(str(span_mins) + 'min').sum()['Volume BTC']\n",
    "    df['vol_btc'] = vols.loc[c_dts].reset_index()['Volume BTC']\n",
    "fetch_trade_vol(thirty_mins_span, 30)\n",
    "fetch_trade_vol(one_h_span, 60)\n",
    "fetch_trade_vol(two_h_span, 120)\n",
    "fetch_trade_vol(fifteen_mins_span, 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty_mins_span\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thirty_diff = thirty_mins_span[['pos_percent', 'neu_percent', 'neg_percent']].diff(periods = 2)\n",
    "thirty_difs = thirty_diff.shift(-1)\n",
    "thirty_difs.rename(columns={'pos_percent': 'pos_change', 'neu_percent': 'neu_change', 'neg_percent': 'neg_change'}, inplace=True)\n",
    "thirty_mins_span_j = thirty_mins_span.join(thirty_difs)\n",
    "\n",
    "\n",
    "one_h_diff = one_h_span[['pos_percent', 'neu_percent', 'neg_percent']].diff(periods = 2)\n",
    "one_h_difs = one_h_diff.shift(-1)\n",
    "one_h_difs.rename(columns={'pos_percent': 'pos_change', 'neu_percent': 'neu_change', 'neg_percent': 'neg_change'}, inplace=True)\n",
    "one_h_span_j = one_h_span.join(one_h_difs)\n",
    "\n",
    "two_h_diff = two_h_span[['pos_percent', 'neu_percent', 'neg_percent']].diff(periods = 2)\n",
    "two_h_difs = two_h_diff.shift(-1)\n",
    "two_h_difs.rename(columns={'pos_percent': 'pos_change', 'neu_percent': 'neu_change', 'neg_percent': 'neg_change'}, inplace=True)\n",
    "two_h_span_j = two_h_span.join(two_h_difs)\n",
    "\n",
    "fifteen_mins_diff = fifteen_mins_span[['pos_percent', 'neu_percent', 'neg_percent']].diff(periods = 2)\n",
    "fifteen_mins_difs = fifteen_mins_diff.shift(-1)\n",
    "fifteen_mins_difs.rename(columns={'pos_percent': 'pos_change', 'neu_percent': 'neu_change', 'neg_percent': 'neg_change'}, inplace=True)\n",
    "fifteen_mins_span_j = fifteen_mins_span.join(fifteen_mins_difs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty_pdiff = thirty_mins_span[['pos_percent', 'neu_percent', 'neg_percent']].diff(periods = 1)\n",
    "thirty_pdiff.rename(columns={'pos_percent': 'pos_pre_change', 'neu_percent': 'neu_pre_change', 'neg_percent': 'neg_pre_change'}, inplace=True)\n",
    "thirty_mins_span_j = thirty_mins_span_j.join(thirty_pdiff)\n",
    "\n",
    "one_h_pdiff = one_h_span[['pos_percent', 'neu_percent', 'neg_percent']].diff(periods = 1)\n",
    "one_h_pdiff.rename(columns={'pos_percent': 'pos_pre_change', 'neu_percent': 'neu_pre_change', 'neg_percent': 'neg_pre_change'}, inplace=True)\n",
    "one_h_span_j = one_h_span_j.join(one_h_pdiff)\n",
    "\n",
    "two_h_pdiff = two_h_span[['pos_percent', 'neu_percent', 'neg_percent']].diff(periods = 1)\n",
    "two_h_pdiff.rename(columns={'pos_percent': 'pos_pre_change', 'neu_percent': 'neu_pre_change', 'neg_percent': 'neg_pre_change'}, inplace=True)\n",
    "two_h_span_j = two_h_span_j.join(two_h_pdiff)\n",
    "\n",
    "fifteen_mins_pdiff = fifteen_mins_span[['pos_percent', 'neu_percent', 'neg_percent']].diff(periods = 1)\n",
    "fifteen_mins_pdiff.rename(columns={'pos_percent': 'pos_pre_change', 'neu_percent': 'neu_pre_change', 'neg_percent': 'neg_pre_change'}, inplace=True)\n",
    "fifteen_mins_span_j = fifteen_mins_span_j.join(fifteen_mins_pdiff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_shift_target(df):\n",
    "    df['shift1_up'] = np.where(df['2spanp'] >  df['1spanp'], 1, 0)\n",
    "    df['shift2_up'] = np.where(df['3spanp'] >  df['2spanp'], 1, 0)\n",
    "    df['shift3_up'] = np.where(df['4spanp'] >  df['3spanp'], 1, 0)\n",
    "\n",
    "assign_shift_target(thirty_mins_span_j)\n",
    "assign_shift_target(one_h_span_j)\n",
    "assign_shift_target(two_h_span_j)\n",
    "assign_shift_target(fifteen_mins_span_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_h_span_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty_mins_span_final = thirty_mins_span_j[['total', 'pos_percent', 'neu_percent', 'neg_percent', 'vol_btc', 'pos_change', 'neu_change', 'neg_change', 'pos_pre_change', 'neu_pre_change', 'neg_pre_change', 'shift1_up', 'shift2_up', 'shift3_up']]\n",
    "one_h_span_final = one_h_span_j[['total', 'pos_percent', 'neu_percent', 'neg_percent', 'vol_btc', 'pos_change', 'neu_change', 'neg_change', 'pos_pre_change', 'neu_pre_change', 'neg_pre_change','shift1_up', 'shift2_up', 'shift3_up']]\n",
    "two_h_span_final = two_h_span_j[['total', 'pos_percent', 'neu_percent', 'neg_percent', 'vol_btc', 'pos_change', 'neu_change', 'neg_change', 'pos_pre_change', 'neu_pre_change', 'neg_pre_change','shift1_up', 'shift2_up', 'shift3_up']]\n",
    "fifteen_mins_span_final = fifteen_mins_span_j[['total', 'pos_percent', 'neu_percent', 'neg_percent', 'vol_btc', 'pos_change', 'neu_change', 'neg_change', 'pos_pre_change', 'neu_pre_change', 'neg_pre_change','shift1_up', 'shift2_up', 'shift3_up']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    TimeSeriesSplit,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thirty_mins_span_final.shape\n",
    "#one_h_span_final.shape\n",
    "#two_h_span.shape\n",
    "fifteen_mins_span_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 2000\n",
    "thirty_train_df = thirty_mins_span_final[:2500]\n",
    "thirty_test_df = thirty_mins_span_final[2500:]\n",
    "\n",
    "one_h_train_df = one_h_span_final[:1600]\n",
    "one_h_test_df = one_h_span_final[1600:]\n",
    "\n",
    "two_h_train_df = two_h_span_final[:500]\n",
    "two_h_test_df = two_h_span_final[500:]\n",
    "\n",
    "fifteen_mins_train_df = fifteen_mins_span_final[:6000]\n",
    "fifteen_mins_test_df = fifteen_mins_span_final[6000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "plt.plot(thirty_train_df['pos_percent'], \"b\", label=\"train\")\n",
    "plt.plot(thirty_test_df['pos_percent'], \"r\", label=\"test\")\n",
    "plt.xticks(rotation=\"vertical\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"pos_percent\",\n",
    "    \"neu_percent\",\n",
    "    \"neg_percent\",\n",
    "    \"pos_change\",\n",
    "    \"neu_change\",\n",
    "    \"neg_change\",\n",
    "    \"pos_pre_change\",\n",
    "    \"neu_pre_change\",\n",
    "    \"neg_pre_change\",\n",
    "    \"vol_btc\",\n",
    "    \"total\"\n",
    "]\n",
    "categorical_features = [\n",
    "    \n",
    "]\n",
    "drop_features = [\n",
    "    \"shift1_up\",\n",
    "    \"shift2_up\",\n",
    "    \"shift3_up\",\n",
    "  \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    numeric_features,\n",
    "    categorical_features,\n",
    "    drop_features,\n",
    "):\n",
    "\n",
    "    all_features = set(numeric_features + categorical_features + drop_features)\n",
    "    if set(train_df.columns) != all_features:\n",
    "        print(\"Missing columns\", set(train_df.columns) - all_features)\n",
    "        print(\"Extra columns\", all_features - set(train_df.columns))\n",
    "        raise Exception(\"Columns do not match\")\n",
    "\n",
    "    numeric_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy=\"median\"), StandardScaler()\n",
    "    )\n",
    "    '''categorical_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy=\"constant\", fill_value=\"?\"),\n",
    "        OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    "    )'''\n",
    "\n",
    "    preprocessor = make_column_transformer(\n",
    "        (numeric_transformer, numeric_features),\n",
    "        #(categorical_transformer, categorical_features),\n",
    "        (\"drop\", drop_features),\n",
    "    )\n",
    "    preprocessor.fit(train_df)\n",
    "    '''ohe_feature_names = (\n",
    "        preprocessor.named_transformers_[\"pipeline-2\"]\n",
    "        .named_steps[\"onehotencoder\"]\n",
    "        .get_feature_names()\n",
    "        .tolist()\n",
    "    )'''\n",
    "    #new_columns = numeric_features + ohe_feature_names\n",
    "    new_columns = numeric_features\n",
    "    X_train_enc = pd.DataFrame(\n",
    "        preprocessor.transform(train_df), index=train_df.index, columns=new_columns\n",
    "    )\n",
    "    X_test_enc = pd.DataFrame(\n",
    "        preprocessor.transform(test_df), index=test_df.index, columns=new_columns\n",
    "    )\n",
    "\n",
    "    y_train = train_df[\"shift2_up\"]\n",
    "    y_test = test_df[\"shift2_up\"]\n",
    "\n",
    "    return X_train_enc, y_train, X_test_enc, y_test, preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc, y_train, X_test_enc, y_test, preprocessor = preprocess_features(\n",
    "    fifteen_mins_train_df,\n",
    "    fifteen_mins_test_df,\n",
    "    numeric_features,\n",
    "    categorical_features,\n",
    "    drop_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_lr_print_coeff(preprocessor, train_df, y_train, test_df, y_test, X_train_enc):\n",
    "    lr_pipe = make_pipeline(preprocessor, LogisticRegression(max_iter=1000))\n",
    "    lr_pipe.fit(train_df, y_train)\n",
    "    print(\"Train score: {:.2f}\".format(lr_pipe.score(train_df, y_train)))\n",
    "    print(\"Test score: {:.2f}\".format(lr_pipe.score(test_df, y_test)))\n",
    "    lr_coef = pd.DataFrame(\n",
    "        data=lr_pipe.named_steps[\"logisticregression\"].coef_.flatten(),\n",
    "        index=X_train_enc.columns,\n",
    "        columns=[\"Coef\"],\n",
    "    )\n",
    "    return lr_coef.sort_values(by=\"Coef\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30mins, 0930-0720, train 0.55, test 0.53, 1 shift\n",
    "score_lr_print_coeff(preprocessor, fifteen_mins_train_df, y_train, fifteen_mins_test_df, y_test, X_train_enc)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
