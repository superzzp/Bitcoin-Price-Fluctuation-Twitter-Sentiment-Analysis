{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "import ssl\n",
    "import certifi\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 13:36:45.458086: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ../models/cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "#model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "#model.save_pretrained(save_directory='../models/' + MODEL)\n",
    "#tokenizer.save_pretrained(save_directory='../models/' + MODEL)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('../models/' + MODEL, local_files_only=True)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained('../models/' + MODEL, local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download label mapping\n",
    "labels=[]\n",
    "task='sentiment'\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link, context=ssl.create_default_context(cafile=certifi.where())) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00341765 0.31853524 0.67804724]\n",
      "negative\n",
      "neutral\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "# # TF Examples\n",
    "#Yeah exactly, dxy is pumping and every thing is still green.. SPX and DJI and BTC.. struggling yeah, but not dumping though, given that bulls and bears are calling for the 38k.. üíÅüèª‚Äç‚ôÇÔ∏è So where do you see us go from here? In the next weeks and until the end of year?\n",
    "#\"I think bitcoin is really on the verge of getting broad acceptance by conventional finance people\"\n",
    "#neu1 = \"WHY CHINA‚ÄôS RENEWED HARSH CRACKDOWN ON CRYPTO ISN‚ÄôT STIFLING BITCOIN ‚Äî AT LEAST NOT YET #bitcoin #btc\"\n",
    "#text1 = \"If Bitcoin was able to capture a $1T market cap, it's not even impossible at this point. It might take time. But there is a chance.\"\n",
    "positive = \"If SEC approves the one of the ETF‚Äôs , this will allow people and instutitional investors to buy bitcoin easier.\"\n",
    "#neg1 = \"yesterday $btc suffered the largest percentage drop in a single day since june 21stüìâ, falling by almost $6,000! are you buying the dip or do you think we'll see more downside? bet on the price of (‚¨ÜÔ∏è or ‚¨áÔ∏è) with up to x1000 leverageüëâ:\"\n",
    "#neg2 = \"problems continue to plague el salvador's bitcoin rollout\"\n",
    "def predict(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='tf')\n",
    "    output = model(encoded_input)\n",
    "    scores = output[0][0].numpy()\n",
    "    scores = softmax(scores)\n",
    "    print(scores)\n",
    "    print(labels[0])\n",
    "    print(labels[1])\n",
    "    print(labels[2])\n",
    "    \"\"\"ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    for i in range(scores.shape[0]):\n",
    "        l = labels[ranking[i]]\n",
    "        s = scores[ranking[i]]\n",
    "        print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\"\"\"\n",
    "predict(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "#load preprocessed dataset\n",
    "data = pd.read_csv('../data/processed/bitcoin_tweets_result_processed_20211001-20220130.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8919051, 13)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8919051 entries, 0 to 9168746\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Dtype \n",
      "---  ------             ----- \n",
      " 0   id                 int64 \n",
      " 1   date               object\n",
      " 2   text               object\n",
      " 3   hashtags           object\n",
      " 4   replyCount         int64 \n",
      " 5   retweetCount       int64 \n",
      " 6   likeCount          int64 \n",
      " 7   userName           object\n",
      " 8   userFollowerCount  int64 \n",
      " 9   userFavCount       int64 \n",
      " 10  userFriendCount    int64 \n",
      " 11  dateTime           object\n",
      " 12  textLength         int64 \n",
      "dtypes: int64(8), object(5)\n",
      "memory usage: 952.7+ MB\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1618690, 13)\n",
      "the number of selected texts: 1618690\n",
      "estimated completion time: 71.94177777777777 hours\n"
     ]
    }
   ],
   "source": [
    "#select a slice of the dataset for prediction, based on dateTime\n",
    "#data = data.drop(['Unnamed: 0'])\n",
    "\n",
    "sData = data[(data['dateTime'] >= '2022-01-10') & (data['dateTime'] < '2022-01-30')]\n",
    "\n",
    "sData = sData.dropna(subset=['text'])\n",
    "\n",
    "print(sData[sData['text'].map(type)== str].shape) \n",
    "\n",
    "print('the number of selected texts:', sData.shape[0])\n",
    "\n",
    "print('estimated completion time:', sData.shape[0] * 0.16 / 60 / 60, 'hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: all countries can now invest üá∫üá≥üá¶üá´üá¶üáΩüá¶üá±üá¶üáÆüá¶üá¥üá¶üá©üá¶üá∏üá©üáøüá¶üá∂üá¶üá¨üá¶üá∑üá¶üá≤üá¶üáºüáßüá≠üáßüá∏üá¶üáøüá¶üáπüá¶üá∫üáßüá©üáßüáßüáßüáæüáßüá™üáßüáøüáßüá¶üáßüá¥üáßüáπüáßüá≤üáßüáØüáßüáºüáßüá∑üáÆüá¥üáªüá¨üá®üá≤üáßüá≥üá∞üá≠üáßüáÆüáßüá´üáßüá¨üá®üá¶üáÆüá®üá®üáªüáßüá∂üá∞üáæüá®üáΩüá®üá≥üá®üá±üáπüá©üá®üá´üá®üá®üá®üá¥üá∞üá≤üá®üá¨üá®üá©üá®üá∫üá≠üá∑üá®üáÆüá®üá∑üá®üá∞üá®üáºüá®üáæüá®üáøüá©üá∞üá©üáØüá∏üáªüá™üá¨üá™üá®üá©üá¥üá©üá≤üá¨üá∂üá™üá∑üá™üá™üá∏üáøüá™üáπüá´üáÆüá´üáØüá´üá¥üá´üá∞üá™üá∫üá´üá∑üá¨üá´üáµüá´üáπüá´üá¨üá¶üá¨üáÆüá¨üá≠üá©üá™üá¨üá™üá¨üá≤üá¨üá∑üá¨üá±üá¨üá©üá¨üáµüá¨üá∫üá¨üáæüá¨üáºüá¨üá≥üá¨üá¨üá¨üáπüá≠üáπüá≠üá≥üá≠üá∞üá≠üá∫üáÆüá∏üáÆüá™üáÆüá∂üáÆüá∑üáÆüá©üáÆüá≥üáÆüá≤üáÆüá±üáÆüáπüáØüá≤üáØüáµüá∞üá™üá∞üáøüáØüá¥üáØüá™\n",
      "error: all countries can now invest üá∫üá≥üá¶üá´üá¶üáΩüá¶üá±üá¶üáÆüá¶üá¥üá¶üá©üá¶üá∏üá©üáøüá¶üá∂üá¶üá¨üá¶üá∑üá¶üá≤üá¶üáºüáßüá≠üáßüá∏üá¶üáøüá¶üáπüá¶üá∫üáßüá©üáßüáßüáßüáæüáßüá™üáßüáøüáßüá¶üáßüá¥üáßüáπüáßüá≤üáßüáØüáßüáºüáßüá∑üáÆüá¥üáªüá¨üá®üá≤üáßüá≥üá∞üá≠üáßüáÆüáßüá´üáßüá¨üá®üá¶üáÆüá®üá®üáªüáßüá∂üá∞üáæüá®üáΩüá®üá≥üá®üá±üáπüá©üá®üá´üá®üá®üá®üá¥üá∞üá≤üá®üá¨üá®üá©üá®üá∫üá≠üá∑üá®üáÆüá®üá∑üá®üá∞üá®üáºüá®üáæüá®üáøüá©üá∞üá©üáØüá∏üáªüá™üá¨üá™üá®üá©üá¥üá©üá≤üá¨üá∂üá™üá∑üá™üá™üá∏üáøüá™üáπüá´üáÆüá´üáØüá´üá¥üá´üá∞üá™üá∫üá´üá∑üá¨üá´üáµüá´üáπüá´üá¨üá¶üá¨üáÆüá¨üá≠üá©üá™üá¨üá™üá¨üá≤üá¨üá∑üá¨üá±üá¨üá©üá¨üáµüá¨üá∫üá¨üáæüá¨üáºüá¨üá≥üá¨üá¨üá¨üáπüá≠üáπüá≠üá≥üá≠üá∞üá≠üá∫üáÆüá∏üáÆüá™üáÆüá∂üáÆüá∑üáÆüá©üáÆüá≥üáÆüá≤üáÆüá±üáÆüáπüáØüá≤üáØüáµüá∞üá™üá∞üáøüáØüá¥üáØüá™\n"
     ]
    }
   ],
   "source": [
    "#apply prediction on texts\n",
    "def predict(text):\n",
    "    try:\n",
    "        encoded_input = tokenizer(text, return_tensors='tf')\n",
    "        output = model(encoded_input)\n",
    "        scores = output[0][0].numpy()\n",
    "        scores = softmax(scores)\n",
    "        negative = np.round(float(scores[0]), 4)\n",
    "        neutral = np.round(float(scores[1]), 4)\n",
    "        positive = np.round(float(scores[2]), 4)\n",
    "        ranking = np.argsort(scores)\n",
    "        ranking = ranking[::-1]\n",
    "        prediction = labels[ranking[0]]\n",
    "        #score = scores[ranking[0]]\n",
    "        #confidence = np.round(float(score), 4)\n",
    "        return pd.Series([prediction, negative, neutral, positive])\n",
    "    except:\n",
    "        print('error:', text)\n",
    "        return pd.Series(['unknown', 0,0,0])\n",
    "\n",
    "#btcdata['sentiment'] = btcdata['text'].apply(lambda x: x.lower())\n",
    "sData[['prediction','negative', 'neutral', 'positive']] = sData['text'].apply(lambda x: predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>userName</th>\n",
       "      <th>userFollowerCount</th>\n",
       "      <th>userFavCount</th>\n",
       "      <th>userFriendCount</th>\n",
       "      <th>dateTime</th>\n",
       "      <th>textLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1487576284834287618</td>\n",
       "      <td>2022-01-29 23:59:58+00:00</td>\n",
       "      <td>where are all my north carolina bitcoin lovers...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>TheCoinDad</td>\n",
       "      <td>4988</td>\n",
       "      <td>7414</td>\n",
       "      <td>507</td>\n",
       "      <td>2022-01-29 23:59:58+00:00</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1487576278139998208</td>\n",
       "      <td>2022-01-29 23:59:57+00:00</td>\n",
       "      <td>closed at break even. waiting for btc direction.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>thouughtless</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>37</td>\n",
       "      <td>2022-01-29 23:59:57+00:00</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1487576273647902720</td>\n",
       "      <td>2022-01-29 23:59:56+00:00</td>\n",
       "      <td>i'm not a fan of elon but putting your life sa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AlienParty</td>\n",
       "      <td>213</td>\n",
       "      <td>5408</td>\n",
       "      <td>671</td>\n",
       "      <td>2022-01-29 23:59:56+00:00</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1487576272574324738</td>\n",
       "      <td>2022-01-29 23:59:55+00:00</td>\n",
       "      <td>if chlamydia could talk‚Ä¶</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>65</td>\n",
       "      <td>598</td>\n",
       "      <td>maxkeiser</td>\n",
       "      <td>449479</td>\n",
       "      <td>18817</td>\n",
       "      <td>1724</td>\n",
       "      <td>2022-01-29 23:59:55+00:00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1487576268304367618</td>\n",
       "      <td>2022-01-29 23:59:54+00:00</td>\n",
       "      <td>btc outperformed eth from 2009- 2015. but eth ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Spicytaco34</td>\n",
       "      <td>11</td>\n",
       "      <td>733</td>\n",
       "      <td>353</td>\n",
       "      <td>2022-01-29 23:59:54+00:00</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                       date  \\\n",
       "0  1487576284834287618  2022-01-29 23:59:58+00:00   \n",
       "1  1487576278139998208  2022-01-29 23:59:57+00:00   \n",
       "2  1487576273647902720  2022-01-29 23:59:56+00:00   \n",
       "3  1487576272574324738  2022-01-29 23:59:55+00:00   \n",
       "4  1487576268304367618  2022-01-29 23:59:54+00:00   \n",
       "\n",
       "                                                text hashtags  replyCount  \\\n",
       "0  where are all my north carolina bitcoin lovers...      NaN           1   \n",
       "1   closed at break even. waiting for btc direction.      NaN           1   \n",
       "2  i'm not a fan of elon but putting your life sa...      NaN           2   \n",
       "3                           if chlamydia could talk‚Ä¶      NaN          84   \n",
       "4  btc outperformed eth from 2009- 2015. but eth ...      NaN           2   \n",
       "\n",
       "   retweetCount  likeCount      userName  userFollowerCount  userFavCount  \\\n",
       "0             2         15    TheCoinDad               4988          7414   \n",
       "1             0          0  thouughtless                  2            11   \n",
       "2             0          0    AlienParty                213          5408   \n",
       "3            65        598     maxkeiser             449479         18817   \n",
       "4             0          1   Spicytaco34                 11           733   \n",
       "\n",
       "   userFriendCount                   dateTime  textLength  \n",
       "0              507  2022-01-29 23:59:58+00:00          75  \n",
       "1               37  2022-01-29 23:59:57+00:00          48  \n",
       "2              671  2022-01-29 23:59:56+00:00          91  \n",
       "3             1724  2022-01-29 23:59:55+00:00          24  \n",
       "4              353  2022-01-29 23:59:54+00:00          82  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sData.groupby('date')['id'].count()\n",
    "sData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/interim/bitcoin_all_tweets_sentiments_20211001-20220130.csv'\n",
    "file_exists = os.path.isfile(filename)\n",
    "\n",
    "#Open/create a file to append data to\n",
    "#csvFile = open(filename, 'a', newline='', encoding='utf8')\n",
    "\n",
    "#Use csv writer\n",
    "#csvWriter = csv.writer(csvFile)\n",
    "if not file_exists:\n",
    "    sData.to_csv(filename, mode='w')\n",
    "sData.to_csv(filename, mode='a', header=False)\n",
    "#csvFile.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
